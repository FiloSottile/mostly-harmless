<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[PyTux]]></title>
  <link href="http://filosottile.github.com/atom.xml" rel="self"/>
  <link href="http://filosottile.github.com/"/>
  <updated>2013-07-29T22:06:36+02:00</updated>
  <id>http://filosottile.github.com/</id>
  <author>
    <name><![CDATA[Filippo Valsorda]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    
      <title type="html"><![CDATA[Javascript Crypto is not Inherently Broken, Only it isn't Inherently a Solution]]></title>
      <link href="http://filosottile.github.com/javascript-crypto-is-not-inherently-broken/"/>
    
    <updated>2013-05-27T08:15:00+02:00</updated>
    <id>http://filosottile.github.com/javascript-crypto-is-not-inherently-broken</id>
    
      <content type="html"><![CDATA[<p><em>This is a long IMHO on the Javascript Crypto <a href="https://news.ycombinator.com/item?id=5768837">discussion</a>, that flourished following the re-publication of <a href="http://log.nadim.cc/?p=33">a post</a> by Nadim Kobeissi in response to <a href="http://www.matasano.com/articles/javascript-cryptography/">an article</a> by Matasano.</em></p>

<p>First, full disclosure: I don’t Know Nadim much, but I respect his work and like his goals; on the other hand, I’m a big Matasano fan, I found <a href="x">their quizzes</a> awesome (go check them out!) and honestly I would sign a deal with the devil to work for them. Moreover, the people involved in the discussion are amongst the ones I admire most.</p>

]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[A bug worth 4200$]]></title>
      <link href="http://filosottile.github.com/a-bug-worth-4200%24/"/>
    
    <updated>2013-04-26T13:04:00+02:00</updated>
    <id>http://filosottile.github.com/a-bug-worth-4200$</id>
    
      <content type="html"><![CDATA[<p><strong>tl;dr</strong> I found a vulnerability in Facebook that allowed anyone to see the “strength” of all his friends’ friendships via a FQL query authenticated with an iOS app access token. The reporting experience has been smooth and not too slow, and the bounty generous.</p>

<p class="img_right"><a href="https://www.facebook.com/BugBounty"><img src="http://filosottile.github.com/images/BugBounty.png" alt="Facebook Bug Bounty" /></a></p>

<p>Early this year Facebook started showing “<em>last active</em>” times above chats in the iOS app but not on the website (they now have rolled out it also in the website) and I started wondering if I could get that info also from my browser and maybe wrap it up in a extension or something (turns out visiting <code>m.facebook.com</code> would have been enough, but emh…). So, I started <a href="http://portswigger.net/burp/proxy.html">Burp Proxy</a> with SSL interception, trusted the Burp CA on my iPad and started inspecting the Facebook iOS app calls.</p>

<!-- more -->

<p>They are mainly <a href="https://developers.facebook.com/docs/technical-guides/fql/"><strong>FQL multiqueries</strong></a>, and one in particular caught my eye (<code>queries</code> parameter URLDecoded for readability):</p>

<pre><code>GET /method/fql.multiquery?sdk=ios&amp;queries={"top_friends":"SELECT uid, online_presence, is_pushable, has_messenger, last_active FROM user WHERE uid in (SELECT uid2 FROM friend WHERE uid1=me() order by communication_rank desc LIMIT 15)","online":"SELECT uid, is_pushable, has_messenger FROM user WHERE online_presence ='active' AND uid IN (SELECT uid2 FROM friend WHERE uid1=me())","favorites":"SELECT uid, online_presence, is_pushable, has_messenger, last_active FROM user WHERE uid in (SELECT favorite_id FROM messaging_favorite WHERE uid=me())","favoriteRanking":"SELECT favorite_id, ordering FROM messaging_favorite WHERE uid=me()"}&amp;sdk_version=2&amp;access_token=REDACTED&amp;format=json&amp;locale=it_IT
</code></pre>

<p>These are a bunch of queries against the <code>user</code> table based on JOINs on the <code>messaging_favorite</code> and <code>friend</code> tables. This <code>friend</code> table is interesting: it holds all the friendships with their details, for example <strong><code>communication_rank</code></strong>. By fiddling around a bit with it I guessed that it is a rank of the <em>“strength”</em> of <code>uid1</code>’s friendship with <code>uid2</code>, probably the thing that decides who’s shown in your chat sidebar even when he’s offline.</p>

<p>The <a href="https://developers.facebook.com/docs/reference/fql/friend">docs</a> tell us that “[the access token owner is] the only user that this table can be queried for, the friends of friends cannot be retrieved”. Hmm. Should we trust the docs? Turns out, <strong>NO</strong>! ;)</p>

<p>Authenticating with our iOS app access token we can issue queries like</p>

<pre><code>SELECT uid2, communication_rank FROM friend WHERE uid1=1289695510 ORDER BY communication_rank DESC
</code></pre>

<p>for an arbitrary friend’s <code>uid1</code> (the above is the one of my favorite guinea pig, Anna) instead of just for ours. That queries return output like</p>

<pre><code>{ "uid2": "1234567890", "communication_rank": "2.4456558227539" },
{ "uid2": "4242424242", "communication_rank": "1.68115234375" },
{ "uid2": "1337133713", "communication_rank": "1.602783203125" },
...
</code></pre>

<p>that tells us with which users the target contacts most, maybe the most interesting and private bit of information after message logs. We don’t even need to be friends of that users!</p>

<h2 id="reporting-and-patching">Reporting and patching</h2>

<p>The first time I reported the issue through <a href="https://www.facebook.com/whitehat/report/">their form</a> it got dismissed, probably also because I didn’t explain it very well. After offering a real world example they confirmed and quickly patched it.</p>

<p>The report netted me a generous 4200$ bounty (delivered as a cool prepaid card, that is worth the withdrawal fee) and a mention on <a href="https://www.facebook.com/whitehat/thanks/">their thanks page</a> (a great, great CV builder), plus some pleasant compliments.</p>

<p class="img_center"><img src="http://filosottile.github.com/images/whitehat.png" alt="White Hat Bounty" /></p>

<p>Facebook offers a great example of how to run a Bug Bounty Program: assure the researcher that he’s being heard, offer him a direct contact (you get ticket-bound <em>Reply-To</em>s) by skilled people, reward him generously (even if, believe me or not, this is the most optional point), publicly thank him and finally let him feel that his work is appreciated.</p>

<h2 id="vulnerability-timeline">Vulnerability timeline</h2>

<table>
  <tbody>
    <tr>
      <td>1 gen 2013</td>
      <td><strong>Vulnerability discovered and bug report filed</strong></td>
    </tr>
    <tr>
      <td>7 gen 2013</td>
      <td>Test accounts POC sent</td>
    </tr>
    <tr>
      <td>18 gen 2013</td>
      <td>First dismissing reply received</td>
    </tr>
    <tr>
      <td>19 gen 2013</td>
      <td><strong>Better explanation and real-users POC sent</strong></td>
    </tr>
    <tr>
      <td>28 gen 2013</td>
      <td>Vulnerability confirmed and acknowledged</td>
    </tr>
    <tr>
      <td>~ 30 gen 2013</td>
      <td><strong>Vulnerability fixed</strong></td>
    </tr>
    <tr>
      <td>1 feb 2013</td>
      <td>Bounty awarded</td>
    </tr>
    <tr>
      <td>18 mar 2013</td>
      <td>Bounty paid</td>
    </tr>
    <tr>
      <td>26 apr 2013</td>
      <td>This public disclosure</td>
    </tr>
  </tbody>
</table>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Claimed a RECAP Aaron Swartz grant &#10150;]]></title>
      <link href="https://www.recapthelaw.org/2013/04/02/two-recap-grants-awarded-in-memory-of-aaron-swartz/"/>
    
    <updated>2013-04-04T21:40:00+02:00</updated>
    <id>http://filosottile.github.com/claimed-a-recap-aaron-swartz-grant</id>
    
      <content type="html"><![CDATA[<p>I’ve recently teamed up with a friend of mine, Alessio Palmero, to extend the reach of the <a href="https://www.recapthelaw.org/">RECAP</a> extension to the Appellate Courts documents and win a <a href="http://www.plainsite.org/aaronsw/index.html">grant</a> offered by PlainSite in memory of <a href="http://www.aaronsw.com/">Aaron Swartz</a>.</p>

<p>The Firefox (and now Chrome) extension intercepts public domain documents downloaded from the pay-walled legal archive <a href="http://www.pacer.gov/">PACER</a> and uploads them to the <a href="http://archive.org/">Internet Archive</a>. Freely available documents are then marked as such for the sake of a juster access to public records.</p>

<p>Details and comments in the linked blog post.</p>

<br><a href="http://filosottile.github.com/claimed-a-recap-aaron-swartz-grant/">Permalink</a>]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Offline storage on a RPi]]></title>
      <link href="http://filosottile.github.com/offline-storage-on-a-rpi/"/>
    
    <updated>2013-02-22T23:21:00+01:00</updated>
    <id>http://filosottile.github.com/offline-storage-on-a-rpi</id>
    
      <content type="html"><![CDATA[<p>The only really secure place for data is <strong>an <a href="https://en.wikipedia.org/wiki/Air_gap_(networking)">offline</a> computer</strong>.</p>

<p>A couple of use cases: <a href="http://wiki.debian.org/subkeys">store your primary <strong>GPG key</strong> offline</a>, without expire date, then generate a couple of subkeys with 1y expiration and use them day to day. This way you will need your primary key only to issue/revoke subkeys or to sign other people keys (and no need to waste all your signatures every time your key expire).
Or, <a href="http://bitcoinarmory.com/using-offline-wallets-in-armory/">create a cold wallet for <strong>Bitcoin</strong> with Armory</a> and authorize all transactions from the offline machine while monitoring them from the online one.
And there are much more examples of data best kept offline…</p>

<p>But not everybody has money and space to keep a rarely used computer around only to store a couple of keys.</p>

<p>My solution is to use a <strong>Raspberry Pi</strong> with a <em>dedicated SD card</em>. Budget: <strong>10$</strong> for the SD (every good nerd already has a RPi, right?). Space: negligible.</p>

<p>If you don’t know what a RPi is, <a href="http://www.raspberrypi.org/faqs">it is a credit card sized computer with Ethernet, USB, HDMI that costs 35$</a>. Now you either want to buy one or you stumbled here by accident.</p>

<p>It’s simple: just download <a href="http://www.raspbian.org/">Raspbian</a>, <strong>unplug Ethernet</strong>, install Gnupg and <a href="https://gist.github.com/FiloSottile/3646033">Armory</a> and transfer data with any USB key! <em>Finish!</em> And now you have highest grade security on the cheap.</p>

]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Programming isn't always easy &#10150;]]></title>
      <link href="http://blog.wizpert.com/programming-help/"/>
    
    <updated>2013-02-21T23:14:00+01:00</updated>
    <id>http://filosottile.github.com/programming-isnt-always-easy</id>
    
      <content type="html"><![CDATA[<p>Since about a month now I’m using the <a href="https://wizpert.com/filippovalsorda">Wizpert</a> platform to help people out with their programming problems. It has been a greatly gratifying experience.</p>

<p>Here is a guest post on their blog.</p>

<p><em>Some people say that with all the reference documentation available, programming is easy.</em> …</p>

<br><a href="http://filosottile.github.com/programming-isnt-always-easy/">Permalink</a>]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Decompressing Lempel-Ziv-Stac in Python]]></title>
      <link href="http://filosottile.github.com/decompressing-lempel-ziv-stac-in-python/"/>
    
    <updated>2013-01-29T12:06:00+01:00</updated>
    <id>http://filosottile.github.com/decompressing-lempel-ziv-stac-in-python</id>
    
      <content type="html"><![CDATA[<p>Lempel-Ziv-Stac is a simple (and a bit exotic) compression algorithm,
used on embedded devices, for example for config files, for example on routers,
for example on those that expose the config file on the public internet. Just sayin’…</p>

<p>There is not a Python implementation of it, so here is my Lempel-Ziv-Stac decompression routine.
<!-- more --></p>
<div><script src="https://gist.github.com/4663892.js"></script>
<noscript><pre><code /></pre></noscript></div>

]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Why Mega WILL change the status quo]]></title>
      <link href="http://filosottile.github.com/why-mega-will-change-the-status-quo/"/>
    
    <updated>2013-01-19T19:23:00+01:00</updated>
    <id>http://filosottile.github.com/why-mega-will-change-the-status-quo</id>
    
      <content type="html"><![CDATA[<p><em>A response to <a href="https://dl.dropbox.com/u/4374976/random/megaless.html">this</a>
on the newly launched <a href="https://mega.co.nz">Mega</a>.</em></p>

<p>It is true that theoretically no sharing approach can solve the problem of being inspectable,
however what Mega does is <strong>eliminate the single point of failure</strong>.</p>

<p>What made sharing over Megaupload difficult and finally killed the service was that
MPAA and RIAA could pressure Mega to obtain access to their data
(remember that they had direct read and delete access to Mega* data),
fingerprint a bunch of files and take down those that matched pirate videos or tracks.</p>

<p><em>Now Mega encrypts client-side all the uploaded data, and gives you the key to store (and share) along with the URL.</em></p>

<p>How this changes the outcome, you ask? Simply stated, <strong>now MPAA and RIAA can’t do anything with access only to Mega infrastructure</strong>.</p>

<p>Obviously key (and URL sharing) is the weakest link in the chain. but consider the two following (common) scenarios:</p>

<h3 id="the-classic-pirate-moviemusic-forumblog">The classic pirate movie/music forum/blog</h3>

<p>The users of those sites always re-uploaded all the content,
as taking the links of another community was considered really unkind and prevented in various ways.</p>

<p>However, all the copies were easy to kill at once by fingerprinting.</p>

<p>Now, instead, a MPAA/RIAA employee (or program) would have to scan through all those disperse, ephemeral and registration-based communities,
in a giant struggle that never comes to an end.</p>

<p>This because <strong>each community will have its own copy of the data, each one requiring its key to be taken down, and each key will have to be fetched from each particular site</strong>.</p>

<p>Do you want to be sure that no one will take down your link? Put it (and its key) behind a CAPTCHA.
This way an automated program will not suffice and they’ll not have enough human resources to check all the forums, blogs, etc.</p>

<h3 id="the-underground-textual-community">The underground textual community</h3>

<p>Let’s say an IRC channel, but also a Skype group chat or Facebook group might work (although I would never share pirate stuff along with my name and surname, but …).</p>

<p>Ever tried sharing big amounts of data over those services? It’s a pain. And sharing with a number of people is plainly impossible.</p>

<p>But now, <strong>one simply upload to Mega the file, and then share link+key with his closed group, and the only way to prevent this is to <em>be part</em> of that group</strong>.</p>

<blockquote>
  <p>This time I have the feeling that the bad guys win.</p>
</blockquote>

<p>P.S. I know that <a href="http://www.matasano.com/articles/javascript-cryptography/">JavaScript crypto is doomed</a> but they are not going to MitM your connection to steal your Mega keys, really.</p>

<p>P.P.S. If you read this far, you might enjoy <a href="https://twitter.com/FiloSottile">following me on Twitter</a></p>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Archive your GitHub repo and data]]></title>
      <link href="http://filosottile.github.com/archive-your-github-repo-and-data/"/>
    
    <updated>2013-01-14T23:17:00+01:00</updated>
    <id>http://filosottile.github.com/archive-your-github-repo-and-data</id>
    
      <content type="html"><![CDATA[<p>GitHub is a service we all trust, so this is not a “get your data off that cloud before it explodes!”-style post,
but sometimes you want to take an offline copy of your or somebody’s work.</p>

<p>Here is a quick and dirty Python script that will help you clone all the repositories, the Gists and some metadata
that can be fetched over the API.
Be warned, it only fetches public repos and data and there’s no error checking.</p>

<div><script src="https://gist.github.com/4710058.js?file=usage.txt"></script>
<noscript><pre><code>usage: gh_dump.py [-h] [--forks] [--no-gist] [--no-metadata] username

Dump an user's public GitHub data into current directory.

positional arguments:
  username       the GH username

optional arguments:
  -h, --help     show this help message and exit
  --forks        git clone also forks (default is don't)
  --no-gist      don't download user gists (default is do)
  --no-metadata  don't download user metadata (default is do)</code></pre></noscript></div>

<div><script src="https://gist.github.com/4710058.js?file=archive_GH.py"></script>
<noscript><pre><code>#!/usr/bin/env python3

# This is free and unencumbered software released into the public domain.

# Anyone is free to copy, modify, publish, use, compile, sell, or
# distribute this software, either in source code form or as a compiled
# binary, for any purpose, commercial or non-commercial, and by any
# means.

# In jurisdictions that recognize copyright laws, the author or authors
# of this software dedicate any and all copyright interest in the
# software to the public domain. We make this dedication for the benefit
# of the public at large and to the detriment of our heirs and
# successors. We intend this dedication to be an overt act of
# relinquishment in perpetuity of all present and future rights to this
# software under copyright law.

# THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR
# OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
# ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
# OTHER DEALINGS IN THE SOFTWARE.

# For more information, please refer to &lt;http://unlicense.org/&gt;

import argparse
from urllib.request import urlopen
from subprocess import call
import json
import re
import os.path

parser = argparse.ArgumentParser(description='Dump an user\'s public GitHub data into current directory.')
parser.add_argument('user', metavar='username',
                   help='the GH username')
parser.add_argument('--forks', dest='forks', action='store_true',
                   help='git clone also forks (default is don\'t)')
parser.add_argument('--no-gist', dest='gists', action='store_false',
                   help='don\'t download user gists (default is do)')
parser.add_argument('--no-metadata', dest='metadata', action='store_false',
                   help='don\'t download user metadata (default is do)')

args = parser.parse_args()

def clear_url(url):
    return re.sub(r'\{[^\}]*\}', '', url)

data = urlopen('https://api.github.com/users/' + args.user).read()
user = json.loads(data.decode('utf-8'))
if args.metadata:
    with open('user.json', 'wb') as f:
        f.write(data)

data = urlopen(clear_url(user['repos_url'])).read()
repos = json.loads(data.decode('utf-8'))
if args.metadata:
    with open('repos.json', 'wb') as f:
        f.write(data)
for repo in repos:
    if not repo['fork']:
        call(['git', 'clone', repo['clone_url']])
    elif args.forks:
        if not os.path.exists('forks'):
            os.makedirs('forks')
        call(['git', 'clone', repo['clone_url'], os.path.join('forks', repo['name'])])

data = urlopen(clear_url(user['gists_url'])).read()
gists = json.loads(data.decode('utf-8'))
if args.metadata:
    with open('gists.json', 'wb') as f:
        f.write(data)
if args.gists:
    if not os.path.exists('gists'):
        os.makedirs('gists')
    for gist in gists:
        call(['git', 'clone', gist['git_pull_url'], os.path.join('gists', gist['id'])])

if args.metadata:
    for name in ['received_events', 'events', 'organizations', 'followers', 'starred', 'following', 'subscriptions']:
        data = urlopen(clear_url(user[name + '_url'])).read()
        with open(name + '.json', 'wb') as f:
            f.write(data)</code></pre></noscript></div>

<p><em>I wrote and used this to archive Aaron Swartz GitHub account on <a href="https://archive.org/details/aaronswGHarchive">archive.org</a>. R.I.P.</em></p>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Automatically compile .less and .coffee files]]></title>
      <link href="http://filosottile.github.com/automatically-compile-less-and-coffee-files/"/>
    
    <updated>2013-01-12T00:25:00+01:00</updated>
    <id>http://filosottile.github.com/automatically-compile-less-and-coffee-files</id>
    
      <content type="html"><![CDATA[<p>This small python script makes use of <a href="http://packages.python.org/watchdog/"><code>watchdog</code></a> (and <a href="http://amoffat.github.com/sh/"><code>sh</code></a>) to monitor your code directory (recursively) and build <a href="http://lesscss.org/">less</a> and <a href="http://coffeescript.org">CoffeeScript</a> files upon edit.</p>

<p>Simply launch it from the relevant folder and it will work in the background.</p>

<p>It should be trivial to add minification (and linting, but I suggest linting in the editor) to the process.</p>

<div><script src="https://gist.github.com/4710041.js?file=watch_and_build.py"></script>
<noscript><pre><code>#!/usr/bin/env python2

import watchdog.events
import watchdog.observers
import sh
import time
import os

# Detach
if os.fork(): os._exit(0)

coffee = sh.coffee.bake('-c')
less = sh.lessc

class Handler(watchdog.events.PatternMatchingEventHandler):
    def __init__(self):
        watchdog.events.PatternMatchingEventHandler.__init__(self, patterns=['*.less', '*.coffee'],
            ignore_directories=True, case_sensitive=False)

    def on_modified(self, event):
        if event.src_path.lower().endswith('.less'):
            try: less(event.src_path, event.src_path[:-5] + '.css')
            except sh.ErrorReturnCode_1 as e: print e.stderr
        if event.src_path.lower().endswith('.coffee'):
            try: coffee(event.src_path)
            except sh.ErrorReturnCode_1 as e: print e.stderr

    on_created = on_modified

if __name__ == &quot;__main__&quot;:
    event_handler = Handler()
    observer = watchdog.observers.Observer()
    observer.schedule(event_handler, path='.', recursive=True)
    observer.start()
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()</code></pre></noscript></div>

<p>It requires <code>coffee</code> (<code>npm install coffee-script</code>) and <code>lessc</code> (<code>npm install less</code>).</p>

<p>Should be compatible with Mac OS X and Linux at least, BSD and Win… maybe.</p>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[GitHub: checkout a pull request as a branch &#10150;]]></title>
      <link href="https://coderwall.com/p/z5rkga"/>
    
    <updated>2013-01-01T06:36:00+01:00</updated>
    <id>http://filosottile.github.com/github-checkout-a-pull-request-as-a-branch</id>
    
      <content type="html"><![CDATA[<p>Today looking at the Travis log of a Pull request build I saw this interesting command:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">git fetch origin +refs/pull/611/merge:</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Turns out that GitHub makes available from your main remote the PR branches as remote refs.</p>

<p>Also (discovered by blind guessing), if you change <code>/merge</code> with <code>/head</code> you get a ref to the clean PR head, unmerged with its target branch. What can be the most useful is up to you, I guess.</p>

<p>This is probably easy because GH on its side stores all the forks of a repo as the same Git repository.</p>

<p>An example in the Coderwall ProTip linked at the title.</p>
<br><a href="http://filosottile.github.com/github-checkout-a-pull-request-as-a-branch/">Permalink</a>]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Krumiro - send a message to all your Facebook friends]]></title>
      <link href="http://filosottile.github.com/krumiro-send-a-message-to-all-your-facebook-friends/"/>
    
    <updated>2012-12-22T19:20:00+01:00</updated>
    <id>http://filosottile.github.com/krumiro-send-a-message-to-all-your-facebook-friends</id>
    
      <content type="html"><![CDATA[<blockquote>
  <p><strong>Disclamer</strong>: this code is published without any guarantee, and <strong>the author is not responsible for any use or consequence deriving from its use</strong>.
By using it you are accepting this and you accept not to consider the author liable for your use.</p>

  <p>For the technically inclined, it’s all under <a href="http://filosottile.mit-license.org">MIT License</a>.</p>
</blockquote>

<p>This is a simple script allowing you to send a message to all your Facebook friends.</p>

<h3 id="features">Features</h3>
<ul>
  <li>Different messages for male and female friends;</li>
  <li>Replace <code>%name</code> with the name of the recipient in the messages (like <code>Hi %name! ...</code>);</li>
  <li>Configurable time to wait between a message and the next, with total duration prediction;</li>
  <li>List of friends to exclude.</li>
</ul>

<p>If you have any request or suggestion, simply leave a comment.</p>

<h3 id="installation">Installation</h3>
<ul>
  <li>Drag this “<a href="javascript:(function(d){var js, ref = d.getElementsByTagName('script')[0];js = d.createElement('script'); js.async = true;js.src = 'https://gist.github.com/raw/4215248/krumiro_en.js';ref.parentNode.insertBefore(js, ref);}(document));">Krumiro</a>” to your bookmarks bar;</li>
  <li>Done! Now the Krumiro button is ready.</li>
</ul>

<h3 id="use">Use</h3>
<ul>
  <li>While on a Facebook page, simply click it;</li>
  <li>Some windows asking you what to do will show up;</li>
  <li>The page will freeze until the script has finished, go grab a coffee, and maybe <a href="https://www.twitter.com">follow me on Twitter</a>.
<!-- more --></li>
</ul>

<h3 id="code-for-the-curious---its-ugly">Code (for the curious - it’s ugly)</h3>
<div><script src="https://gist.github.com/4215248.js?file=krumiro_en.js"></script>
<noscript><pre><code>var msg_m_prompt = 'Insert the message for males. I\'ll replace %name with the recipient name.';
var msg_f_prompt = 'Insert the message for females. I\'ll replace %name with the recipient name.';
var throttle_prompt = 'Insert the pause in milliseconds between a friend and the next.';
var exclude_prompt = 'Insert the list of friends to ignore, comma separated.';
var exerror_alert = '%s is not in your friends, you might have made a mistake. Do you want to continue?';
var time_alert = 'The script will take %s seconds!';
var done = 'Done!';

if(!Array.prototype.indexOf){Array.prototype.indexOf=function(d){if(void 0===this||null===this)throw new TypeError;var c=Object(this),b=c.length&gt;&gt;&gt;0;if(0===b)return-1;var a=0;0&lt;arguments.length&amp;&amp;(a=Number(arguments[1]),a!==a?a=0:0!==a&amp;&amp;(a!==1/0&amp;&amp;a!==-(1/0))&amp;&amp;(a=(0&lt;a||-1)*Math.floor(Math.abs(a))));if(a&gt;=b)return-1;for(a=0&lt;=a?a:Math.max(b-Math.abs(a),0);a&lt;b;a++)if(a in c&amp;&amp;c[a]===d)return a;return-1};}

function size(obj) {
    var s = 0, key;
    for (key in obj) {
        if (obj.hasOwnProperty(key)) s++;
    }
    return s;
}

function sleep(milliseconds) {
    var start = new Date().getTime();
    for (var i = 0; i &lt; 1e7; i++) {
        if ((new Date().getTime() - start) &gt; milliseconds){
          break;
        }
    }
}

function send(msg, to) {
    function serialize(obj) {
      var str = [];
      for(var p in obj)
         str.push(p + &quot;=&quot; + encodeURIComponent(obj[p]));
      return str.join(&quot;&amp;&quot;);
    }
    function random(len) {
        var min = Math.pow(10, len-1);
        var max = Math.pow(10, len);
        return Math.floor(Math.random() * (max - min + 1)) + min;
    }
    function generatePhstamp(qs, dtsg) {
        var input_len = qs.length;
        numeric_csrf_value='';

        for(var ii=0;ii&lt;dtsg.length;ii++) {
            numeric_csrf_value+=dtsg.charCodeAt(ii);
        }
        return '1' + numeric_csrf_value + input_len;
    }
    var fbid = window.require('Env').user;
    var d = new Date();
    var data = {
       &quot;message_batch[0][timestamp_relative]&quot;: &quot;&quot; + ('0'+d.getHours()).slice(-2) + &quot;:&quot; + ('0'+d.getMinutes()).slice(-2), 
       &quot;message_batch[0][author]&quot;: &quot;fbid:&quot; + fbid, 
       &quot;message_batch[0][is_cleared]&quot;: &quot;false&quot;, 
       &quot;message_batch[0][message_id]&quot;: &quot;&lt;&quot; + random(14) + &quot;:&quot; + random(10) + &quot;-&quot; + random(10) + &quot;@mail.projektitan.com&gt;&quot;, 
       &quot;message_batch[0][specific_to_list][0]&quot;: &quot;fbid:&quot; + to, 
       &quot;__user&quot;: fbid, 
       &quot;message_batch[0][timestamp_absolute]&quot;: &quot;Oggi&quot;, 
       &quot;message_batch[0][spoof_warning]&quot;: &quot;false&quot;, 
       &quot;message_batch[0][client_thread_id]&quot;: &quot;user:&quot; + to, 
       &quot;message_batch[0][source]&quot;: &quot;source:chat:web&quot;, 
       &quot;message_batch[0][has_attachment]&quot;: &quot;false&quot;, 
       &quot;message_batch[0][source_tags][0]&quot;: &quot;source:chat&quot;, 
       &quot;message_batch[0][body]&quot;: msg, 
       &quot;message_batch[0][is_filtered_content]&quot;: &quot;false&quot;, 
       &quot;message_batch[0][timestamp]&quot;: &quot;&quot; + Math.round(new Date().getTime() / 1000), 
       &quot;message_batch[0][is_unread]&quot;: &quot;false&quot;, 
       &quot;message_batch[0][action_type]&quot;: &quot;ma-type:user-generated-message&quot;, 
       &quot;__a&quot;: &quot;1&quot;, 
       &quot;message_batch[0][specific_to_list][1]&quot;: &quot;fbid:&quot; + fbid, 
       &quot;message_batch[0][html_body]&quot;: &quot;false&quot;, 
       &quot;message_batch[0][status]&quot;: &quot;0&quot;, 
       &quot;client&quot;: &quot;mercury&quot;, 
       &quot;message_batch[0][is_forward]&quot;: &quot;false&quot;, 
       &quot;fb_dtsg&quot;: window.require('Env').fb_dtsg
    };
    var req = serialize(data);
    // Thanks http://pastebin.com/VJAhUw30
    req += &quot;&amp;phstamp=&quot; + generatePhstamp(req, data.fb_dtsg);
    xmlhttp = new XMLHttpRequest();
    xmlhttp.open('POST', '/ajax/mercury/send_messages.php');
    xmlhttp.send(req);
}

function buddy(callback) {
    var xhr = new XMLHttpRequest();
    xhr.open(&quot;GET&quot;, &quot;https://www.facebook.com/ajax/chat/user_info_all.php?__user=&quot; + window.require('Env').user + &quot;&amp;__a=1&amp;viewer=&quot; + window.require('Env').user, true);
    xhr.onreadystatechange = function() {
      if (xhr.readyState == 4) {
        var resp = JSON.parse(xhr.responseText.slice(9));
        callback(resp.payload);
      }
    };
    xhr.send();
}

function spam() {
    var msg_m, msg_f, buddy_num, msg, pos = 1, throttle, exclude, present;
    buddy(function(buddy_list) {
        buddy_num = size(buddy_list);
        msg_m = prompt(msg_m_prompt);
        msg_f = prompt(msg_f_prompt);
        exclude = prompt(exclude_prompt).split(&quot;,&quot;);
        if (exclude.length == 1 &amp;&amp; exclude[0].trim() == '') exclude = Array();
        for (var i = 0; i &lt; exclude.length; i++) {
            present = false;
            for (var id in buddy_list)
                if (buddy_list[id].name == exclude[i].trim()) present = true;
            if (!present)
                if (!confirm(exerror_alert.replace('%s', exclude[i].trim()))) return;
        }
        throttle = +prompt(throttle_prompt);
        if (!confirm(time_alert.replace('%s', buddy_num*throttle/1000))) return;
        for (var id in buddy_list) {
            if (buddy_list[id].gender === 1) msg = msg_f;
            else msg = msg_m;
            msg = msg.replace('%name', buddy_list[id].firstName);
            // if (buddy_list[id].name == '') send(msg, id);
            if (exclude.indexOf(buddy_list[id].name) == -1) send(msg, id);
            if (pos % Math.floor(buddy_num/100) == 0) console.log(Math.floor(pos/(buddy_num/100)) + ' %');
            pos++;
            sleep(throttle);
        }
        alert(done);
    });
}

spam();</code></pre></noscript></div>

]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Please take this and go signing those updates]]></title>
      <link href="http://filosottile.github.com/please-take-this-and-go-signing-those-updates/"/>
    
    <updated>2012-12-19T20:47:00+01:00</updated>
    <id>http://filosottile.github.com/please-take-this-and-go-signing-those-updates</id>
    
      <content type="html"><![CDATA[<p>If your program does any sort of self-updating, it is <em>fundamental</em> that you <strong>check the update payload integrity</strong>. And no, fetching it over HTTPS might <a href="http://docs.python.org/2/library/urllib2.html">not</a> <a href="http://docs.python.org/3.3/library/urllib.request.html">be</a> <a href="http://www.rubyinside.com/how-to-cure-nethttps-risky-default-https-behavior-4010.html">enough</a>.</p>

<p>Otherwise, anyone who can tamper with the traffic of your users, like anyone on their same network, or their ISP, can trivially get <strong>code execution</strong> by modifying the update while your program downloads it. And yes, <a href="http://www.infobytesec.com/down/isr-evilgrade-Readme.txt">it is exploited in the wild and it is easy</a>.</p>

<p>The common way to sign something is to use RSA, but you might not want to rely on <em>yet another external dependency</em>, with God knows which license…<br />
Then, <strong>take this</strong>! It’s a drop-in, <em>zero-dependency</em> <strong>RSA signature verifying function</strong> that run on Python 2.4+ (seriously) and… it’s in the Public Domain (<a href="http://creativecommons.org/publicdomain/zero/1.0/">CC0</a>), it’s yours.</p>

<div><script src="https://gist.github.com/4340076.js?file=rsa_verify.py"></script>
<noscript><pre><code>def rsa_verify(message, signature, key):
    from struct import pack
    from hashlib import sha256 # You'll need the backport for 2.4 http://code.krypto.org/python/hashlib/
    from sys import version_info
    def b(x):
        if version_info[0] == 2: return x
        else: return x.encode('latin1')
    assert(type(message) == type(b('')))
    block_size = 0
    n = key[0]
    while n:
        block_size += 1
        n &gt;&gt;= 8
    signature = pow(int(signature, 16), key[1], key[0])
    raw_bytes = []
    while signature:
        raw_bytes.insert(0, pack(&quot;B&quot;, signature &amp; 0xFF))
        signature &gt;&gt;= 8
    signature = (block_size - len(raw_bytes)) * b('\x00') + b('').join(raw_bytes)
    if signature[0:2] != b('\x00\x01'): return False
    signature = signature[2:]
    if not b('\x00') in signature: return False
    signature = signature[signature.index(b('\x00'))+1:]
    if not signature.startswith(b('\x30\x31\x30\x0D\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01\x05\x00\x04\x20')): return False
    signature = signature[19:]
    if signature != sha256(message).digest(): return False
    return True</code></pre></noscript></div>

<p><a href="https://gist.github.com/4340076">Here</a> are the instructions on how to generate your private and public keys and how to sign new updates. Don’t worry, it’s all really easy; if you happen to encounter any issues, shoot me a mail at <code>filippo.valsorda -&gt; gmail.com</code>!</p>

<p>I am sufficiently proficient only in Python, so if any C, Perl, PHP or Brainfuck guru wants to show up and contribute the same function in another language, it would be awesome!</p>

<p>Now you don’t have any excuses anymore (at least you Python devs): <strong>go signing your updates</strong>!<br />
(And maybe also <a href="https://www.twitter.com/FiloSottile">following me on Twitter</a>)</p>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Taking Retina screenshots with PhantomJS]]></title>
      <link href="http://filosottile.github.com/taking-retina-screenshots-with-phantomjs/"/>
    
    <updated>2012-05-12T16:44:00+02:00</updated>
    <id>http://filosottile.github.com/taking-retina-screenshots-with-phantomjs</id>
    
      <content type="html"><![CDATA[<p>With <a href="http://phantomjs.org">PhantomJS</a>, a headless WebKit browser with Javascript API, you can automatically render a webpage like you see it on your screen in an image or PDF. This is an awesome feature, useful for testing or - that’s what I use it for - rendering some elements of the page as images for later use.</p>

<p>Here I will explain how to take Retina-like screenshots. These are screenshots with double width and height for the same element where the details are rendered with double the precision. There are different reasons to want that: you might not own a new iPad or an iPhone4* and want to see how your website would look on these devices or you might want to add a Retina unit test to your awesome test stack. I want to render text to images so that they will still look sharp on Retina screens when used as replacements.</p>

<p>The key is the CSS3 <a href="http://www.w3schools.com/css3/css3_2dtransforms.asp"><code>transform</code></a> property and its <code>scale(2)</code> value, plus a couple of tweaks.
<!--more-->
Here is a modified version of the rasterize.js example to output Retina screenshots.</p>
<div><script src="https://gist.github.com/2667199.js?file=rasterize.js"></script>
<noscript><pre><code>var page = require('webpage').create(),
    address, output, size;

if (phantom.args.length &lt; 2 || phantom.args.length &gt; 3) {
    console.log('Usage: rasterize.js URL filename');
    phantom.exit();
} else {
    address = phantom.args[0];
    output = phantom.args[1];
    page.viewportSize = { width: 1280, height: 1024 };
    page.open(address, function (status) {
        if (status !== 'success') {
            console.log('Unable to load the address!');
        } else {
            page.evaluate(function () {
                /* scale the whole body */
                document.body.style.webkitTransform = &quot;scale(2)&quot;;
                document.body.style.webkitTransformOrigin = &quot;0% 0%&quot;;
                /* fix the body width that overflows out of the viewport */
                document.body.style.width = &quot;50%&quot;;
            });
            window.setTimeout(function () {
                page.render(output);
                phantom.exit();
            }, 200);
        }
    });
}</code></pre></noscript></div>

<h3 id="bonus">Bonus</h3>
<p>You might want to render only a single element, for example your content div or your always-buggy sidebar, to an image.<br />
Well, have a look at <a href="https://developer.mozilla.org/en/DOM/element.getBoundingClientRect"><code>element.getBoundingClientRect</code></a> (<a href="http://ejohn.org/blog/getboundingclientrect-is-awesome/">getBoundingClientRect is Awesome</a>) and PhantomJS <a href="https://github.com/ariya/phantomjs/wiki/API-Reference#wiki-webpage-clipRect"><code>page.clipRect</code></a>.</p>

<p>Here is a spoiler ;)</p>
<div><script src="https://gist.github.com/2667279.js?file=gistfile1.js"></script>
<noscript><pre><code>page.clipRect = page.evaluate(function() {
    return document.getElementById(ELEMENT_ID).getBoundingClientRect(); 
});</code></pre></noscript></div>

<h3 id="references">References</h3>
<ul>
  <li><a href="http://fcargoet.evolix.net/2012/01/use-phantomjs-to-take-screenshots-of-you-webapp-for-you/">Use PhantomJS to take screenshots of your webapp for you</a> - /home/florian</li>
  <li><a href="https://github.com/ariya/phantomjs/wiki/Screen-Capture">Rendering QuickStart example</a> - PhantomJs Wiki</li>
  <li><a href="https://github.com/ariya/phantomjs/wiki/API-Reference#wiki-webpage-render"><code>render()</code> API reference</a> </li>
</ul>

]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Send a HEAD request in Python]]></title>
      <link href="http://filosottile.github.com/send-a-head-request-in-python/"/>
    
    <updated>2012-03-18T17:53:00+01:00</updated>
    <id>http://filosottile.github.com/send-a-head-request-in-python</id>
    
      <content type="html"><![CDATA[<p>There are a lot of questions on this topic around the web and common answers are to use <code>httplib</code>, that however is a really-low level library, or to use <code>urllib2</code>, but a lot of people complains about it returning to <code>GET</code> if following a redirect.</p>

<p>Here is my <code>urllib2</code> solution, written looking at the code of <code>urllib2.HTTPRedirectHandler</code> and subclassing it in order to make it keep using the <code>HeadRequest</code>.</p>

<div><script src="https://gist.github.com/2077204.js?file=HEAD-request.py"></script>
<noscript><pre><code>import urllib2

class HeadRequest(urllib2.Request):
    def get_method(self):
        return &quot;HEAD&quot;

class HEADRedirectHandler(urllib2.HTTPRedirectHandler):
    &quot;&quot;&quot;
    Subclass the HTTPRedirectHandler to make it use our 
    HeadRequest also on the redirected URL
    &quot;&quot;&quot;
    def redirect_request(self, req, fp, code, msg, headers, newurl): 
        if code in (301, 302, 303, 307):
            newurl = newurl.replace(' ', '%20') 
            return HeadRequest(newurl, 
                               headers=req.headers, 
                               origin_req_host=req.get_origin_req_host(), 
                               unverifiable=True) 
        else: 
            raise urllib2.HTTPError(req.get_full_url(), code, msg, headers, fp)

# Build our opener with the HEADRedirectHandler
opener = urllib2.OpenerDirector() 
for handler in [urllib2.HTTPHandler, urllib2.HTTPDefaultErrorHandler,
                HEADRedirectHandler,
                urllib2.HTTPErrorProcessor, urllib2.HTTPSHandler]:
    opener.add_handler(handler())

response = opener.open(HeadRequest(url))

print response.geturl()
print response.info()</code></pre></noscript></div>

<p>For example, here is a fast URL un-shortener (redirect follower) realized with the method above (and a fallback).</p>

<div><script src="https://gist.github.com/2077115.js?file=redirect-follower.py"></script>
<noscript><pre><code>#!/usr/bin/env python
#-*- coding:utf-8 -*-

import sys
import urllib2

# This script uses HEAD requests (with fallback in case of 405) 
# to follow the redirect path up to the real URL
# (c) 2012 Filippo Valsorda - FiloSottile
# Released under the GPL license

class HeadRequest(urllib2.Request):
    def get_method(self):
        return &quot;HEAD&quot;

class HEADRedirectHandler(urllib2.HTTPRedirectHandler):
    &quot;&quot;&quot;
    Subclass the HTTPRedirectHandler to make it use our 
    HeadRequest also on the redirected URL
    &quot;&quot;&quot;
    def redirect_request(self, req, fp, code, msg, headers, newurl): 
        if code in (301, 302, 303, 307):
            newurl = newurl.replace(' ', '%20') 
            newheaders = dict((k,v) for k,v in req.headers.items()
                              if k.lower() not in (&quot;content-length&quot;, &quot;content-type&quot;))
            return HeadRequest(newurl, 
                               headers=newheaders,
                               origin_req_host=req.get_origin_req_host(), 
                               unverifiable=True) 
        else: 
            raise urllib2.HTTPError(req.get_full_url(), code, msg, headers, fp) 
            
class HTTPMethodFallback(urllib2.BaseHandler):
    &quot;&quot;&quot;
    Fallback to GET if HEAD is not allowed (405 HTTP error)
    &quot;&quot;&quot;
    def http_error_405(self, req, fp, code, msg, headers): 
        fp.read()
        fp.close()

        newheaders = dict((k,v) for k,v in req.headers.items()
                          if k.lower() not in (&quot;content-length&quot;, &quot;content-type&quot;))
        return self.parent.open(urllib2.Request(req.get_full_url(), 
                                         headers=newheaders, 
                                         origin_req_host=req.get_origin_req_host(), 
                                         unverifiable=True))

# Build our opener
opener = urllib2.OpenerDirector() 
for handler in [urllib2.HTTPHandler, urllib2.HTTPDefaultErrorHandler,
                HTTPMethodFallback, HEADRedirectHandler,
                urllib2.HTTPErrorProcessor, urllib2.HTTPSHandler]:
    opener.add_handler(handler())

response = opener.open(HeadRequest(sys.argv[1]))

print response.geturl()</code></pre></noscript></div>

]]></content>
    
  </entry>
  
</feed>
